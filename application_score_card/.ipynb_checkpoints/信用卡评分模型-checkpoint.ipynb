{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008750.0\n",
      "0.0\n",
      "6670.221237392844\n",
      "0    5000.0\n",
      "dtype: float64\n",
      "5400.0\n",
      "114.0403179452332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:76: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:77: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008750.0\n",
      "0.0\n",
      "6025.802513333333\n",
      "0    1159.0\n",
      "dtype: float64\n",
      "4973.0\n",
      "123.94738320084522\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146076 entries, 0 to 149999\n",
      "Data columns (total 12 columns):\n",
      "Unnamed: 0       146076 non-null int64\n",
      "target           146076 non-null int64\n",
      "percentage       146076 non-null float64\n",
      "age              146076 non-null int64\n",
      "30-59            146076 non-null int64\n",
      "DebtRatio        146076 non-null float64\n",
      "MonthlyIncome    146076 non-null float64\n",
      "open_loan        146076 non-null int64\n",
      "90-              146076 non-null int64\n",
      "estate_loan      146076 non-null int64\n",
      "60-89            146076 non-null int64\n",
      "Dependents       146076 non-null float64\n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 14.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "D:\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "================================================================================\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-100c0f4ae5dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcutx5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m \u001b[0mdfx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mivx3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwoex3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_bin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'30-59'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcutx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[0mdfx4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mivx4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwoex4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_bin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DebtRatio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcutx4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[0mdfx6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mivx6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwoex6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_bin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'open_loan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcutx6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-100c0f4ae5dd>\u001b[0m in \u001b[0;36mself_bin\u001b[1;34m(Y, X, bin)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0mcut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0mcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mqua\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqua\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "# %load appliaction_score_card.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "data_train = pd.read_csv('./data/cs-training.csv')\n",
    "\n",
    "\"\"\"\n",
    "数据说明\n",
    "\n",
    "SeriousDlqin2yrs：违约客户及超过90天逾期客户，bool型；\n",
    "RevolvingUtilizationOfUnsecuredLines：贷款以及信用卡可用额度与总额度比例，百分比；\n",
    "age：用户年龄，整型\n",
    "NumberOfTime30-59DaysPastDueNotWorse：35-59天逾期但不糟糕次数，整型；\n",
    "DebtRatio：负债率，百分比；\n",
    "MonthlyIncome：月收入，整型；\n",
    "NumberOfOpenCreditLinesAndLoans：开放式信贷和贷款数量，开放式贷款（分期付款如汽车贷款或抵押贷款）和信贷（如信用卡）的数量，整型；\n",
    "NumberOfTimes90DaysLate：90天逾期次数：借款者有90天或更高逾期的次数，整型；\n",
    "NumberRealEstateLoansOrLines：不动产贷款或额度数量：抵押贷款和不动产放款包括房屋净值信贷额度，整型；\n",
    "NumberOfTime60-89DaysPastDueNotWorse：60-89天逾期但不糟糕次数：借款人在在过去两年内有60-89天逾期还款但不糟糕的次数，整型；\n",
    "NumberOfDependents：家属数量：不包括本人在内的家属数量，整型；\n",
    "\n",
    "\"\"\"\n",
    "#变量重命名\n",
    "columns = ({'SeriousDlqin2yrs':'target',\n",
    "            'RevolvingUtilizationOfUnsecuredLines':'percentage',\n",
    "           'NumberOfOpenCreditLinesAndLoans':'open_loan',\n",
    "           'NumberOfTimes90DaysLate':'90-',\n",
    "           'NumberRealEstateLoansOrLines':'estate_loan',\n",
    "           'NumberOfTime60-89DaysPastDueNotWorse':'60-89',\n",
    "           'NumberOfDependents':'Dependents',\n",
    "           'NumberOfTime30-59DaysPastDueNotWorse':'30-59'}\n",
    "          )\n",
    "data_train.rename(columns=columns,inplace = True)\n",
    "\n",
    "#查看数据缺失情况并填充缺失值\n",
    "missing_df = data_train.isnull().sum(axis =0).reset_index()\n",
    "missing_df\n",
    "#我们看到'MonthlyIncome'和'NumberOfDependents'有缺失值\n",
    "data_train.MonthlyIncome.isnull().sum()/data_train.shape[0]\n",
    "data_train.Dependents.isnull().sum()/data_train.shape[0]\n",
    "\n",
    "\"\"\"\n",
    "对于缺失值处理，有很多种方法：\n",
    "\n",
    "缺失值极多：若缺失值样本占总数比例极高，直接舍弃，因为作为特征加入反而会引入噪声值（可以使用删除近零常量的方法删除）。\n",
    "非连续特征缺失值适中：如果缺值的样本适中，而该属性非连续值特征属性，就把NaN作为一个新类别，加入到类别特征中。\n",
    "连续特征缺失值适中：如果缺值的样本适中，考虑给定一个step，然后离散化，将NaN作为一个type加入到属性类目中。\n",
    "缺失值较少：考虑利用填充的办法进行处理。其中有均值、众数、中位数填充。\n",
    "用sklearn里的RandomForest/KNN模型去拟合数据样本训练模型，然后去填充缺失值。\n",
    "拉格朗日插值法。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#由于MonthlyIncome缺失值达到29731条数据，比例较大，因此不能直接将缺失值删除，选择随机森林法，将有缺失值的变量分成已知特征和未知特征\n",
    "#（仅含有缺失值），将已知 特征和标签进行训练，得到训练模型，对未知特征进行预测。\n",
    "print(data_train['MonthlyIncome'].max())\n",
    "print(data_train['MonthlyIncome'].min())\n",
    "print(data_train['MonthlyIncome'].mean())\n",
    "print(data_train['MonthlyIncome'].mode())\n",
    "print(data_train['MonthlyIncome'].median())\n",
    "print(data_train['MonthlyIncome'].skew())\n",
    "\n",
    "# 用随机森林对缺失值进行预测\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "  \n",
    "# 预测填充函数\n",
    "def rf_filling(df):\n",
    "    # 处理数集，将monthincome放在第一列\n",
    "    process_miss = df.iloc[:,[6,0,1,2,3,4,5,7,8,9]]\n",
    "    #根据monthincome，分成已知特征与未知特征\n",
    "    known = process_miss[process_miss.MonthlyIncome.notnull()].as_matrix()\n",
    "    unknown = process_miss[process_miss.MonthlyIncome.isnull()].as_matrix()\n",
    "    #X，要训练的特征\n",
    "    X = known[:,1:]\n",
    "    #y ,结果标签\n",
    "    y = known[:,0]\n",
    "    #训练模型\n",
    "    rf = RandomForestRegressor(random_state=0,n_estimators=200,max_depth=3,n_jobs=-1)\n",
    "    rf.fit(X,y)\n",
    "    #预测缺失值\n",
    "    pred = rf.predict( unknown[:,1:]).round(0)\n",
    "    #补缺缺失值\n",
    "    df.loc[df['MonthlyIncome'].isnull(),'MonthlyIncome'] = pred\n",
    "    return df\n",
    "data_train = rf_filling(data_train)\n",
    "\n",
    "print(data_train['MonthlyIncome'].max())\n",
    "print(data_train['MonthlyIncome'].min())\n",
    "print(data_train['MonthlyIncome'].mean())\n",
    "print(data_train['MonthlyIncome'].mode())  #众数\n",
    "print(data_train['MonthlyIncome'].median())\n",
    "print(data_train['MonthlyIncome'].skew())  #偏度\n",
    "\n",
    "#Dependents变量缺失值比较少，直接删除，对总体模型不会造成太大影响。对缺失值处理完之后，删除重复项\n",
    "data_train = data_train.dropna()\n",
    "data_train = data_train.drop_duplicates()\n",
    "data_train.info()\n",
    "\n",
    "\"\"\"\n",
    "异常值处理\n",
    "缺失值处理完毕后，我们还需要进行异常值处理。异常值是指明显偏离大多数抽样数据的数值，比如个人客户的年龄大于100或小于0时，通常认为该值为异常值。找出样本总体中的异常值，通常采用离群值检测的方法。 离群值检测的方法有单变量离群值检测、局部离群值因子检测、基于聚类方法的离群值检测等方法。\n",
    "在本数据集中，采用单变量离群值检测来判断异常值，采用箱线图。\n",
    "\n",
    "\"\"\"\n",
    "#age\n",
    "sns.boxplot(data_train.age,palette = 'Set3',orient = 'v')\n",
    "plt.show()\n",
    "#将age小于0和大于100的值作为离群值删去\n",
    "data_train = data_train[(data_train.age>0)&(data_train.age<100)]\n",
    "\n",
    "#RevolvingUtilizationOfUnsecuredLines 和 DebtRatio\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot([data_train.percentage,data_train.DebtRatio])\n",
    "ax.set_xticklabels(['percentage','DebtRatio'])\n",
    "plt.show()\n",
    "#对于百分比大于1的为异常值，我们尝试分别用两种方法处理：1、直接删除；2、将离群值当空值处理，填充均值\n",
    "data_train = data_train[(data_train.percentage<1)]\n",
    "data_train = data_train[(data_train.DebtRatio<1)]\n",
    "\n",
    "#变量0-59天，60-89天，90-三个异常值处理\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot([data_train['30-59'],data_train['60-89'],data_train['90-']])\n",
    "ax.set_xticklabels(['30-59','60-89','90-'])\n",
    "plt.show()\n",
    "#三个变量都有离群值，查看各个特征离群值数量\n",
    "data_train[data_train['30-59']>60].shape\n",
    "data_train[data_train['60-89']>90].shape\n",
    "data_train[data_train['90-']>90].shape\n",
    "#离群值数量较少，全部删除\n",
    "data_train= data_train[data_train['30-59']<60]\n",
    "data_train = data_train[data_train['60-89']<90]\n",
    "data_train = data_train[data_train['90-']<90]\n",
    "data_train = data_train.reset_index(drop=True)#重设索引\n",
    "\n",
    "#MonthlyIncome\n",
    "sns.boxplot(data_train.MonthlyIncome,palette = 'Set3',orient = 'v')\n",
    "plt.show()\n",
    "data_train[data_train['MonthlyIncome']>50000].shape\n",
    "data_train = data_train[data_train['MonthlyIncome']<50000]\n",
    "data_train = data_train.reset_index(drop=True)#重设索引\n",
    "\n",
    "#EDA.首先分析好坏客户占比情况\n",
    "data_train.target.value_counts().plot(kind = 'bar')\n",
    "plt.show()\n",
    "t = (data_train.target.value_counts()[1])/len(data_train)#坏样本较少，可以考虑采用Smote转换\n",
    "\n",
    "sns.distplot(data_train.age)#基本符合正态分布\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(data_train['MonthlyIncome'])\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(data_train['DebtRatio'])\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(data_train['30-59'])\n",
    "plt.show()\n",
    "#可以考虑使用Box_Cox 转换调整数据的偏度\n",
    "\n",
    "#多变量分析\n",
    "corr = data_train.corr()\n",
    "corr\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "sns.heatmap(corr, annot=True, cmap='YlGnBu', ax=ax1, annot_kws={'size': 9, 'color': 'm'})#绘制相关性系数热力图\n",
    "plt.show()\n",
    "#由上图可以看出，各变量之间的相关性是非常小的，可以初步判断不存在多重共线性问题\n",
    "\n",
    "#特征选择,woe分箱\n",
    "from scipy import stats\n",
    "def monoto_bin(Y, X, n = 20):\n",
    "    r = 0\n",
    "    total_bad = Y.sum()\n",
    "    total_good =Y.count()-total_bad  \n",
    "    while np.abs(r) < 1:\n",
    "        d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Bucket\": pd.qcut(X, n,duplicates='raise')})  #数据框，列为x，y，所属分组区间\n",
    "        d2 = d1.groupby('Bucket', as_index = True)        #基于分组区间分组统计（下一行代码中.mean()\n",
    "        r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)  #计算分组后各组x的均值和y的均值的相关性，r为相关系数，p为p值，如果r<1，则分组数量减一，循环结束后n=3\n",
    "        n = n - 1\n",
    "    d3 = pd.DataFrame(d2.min().X, columns = ['min_' + X.name])\n",
    "    d3['min_' + X.name] = d2.min().X\n",
    "    d3['max_' + X.name] = d2.max().X\n",
    "    d3[Y.name] = d2.sum().Y\n",
    "    d3['total'] = d2.count().Y\n",
    "    #d3[Y.name + '_rate'] = d2.mean().Y\n",
    "    d3['badattr']=d3[Y.name]/total_bad\n",
    "    d3['goodattr']=(d3['total']-d3[Y.name])/total_good\n",
    "    d3['woe'] = np.log(d3['goodattr']/d3['badattr'])\n",
    "    iv = ((d3['goodattr']-d3['badattr'])*d3['woe']).sum()\n",
    "    d4 = (d3.sort_values(by = 'min_' + X.name)).reset_index(drop = True)\n",
    "    print (\"=\" * 80)\n",
    "    cut = []\n",
    "    cut.append(float('-inf'))   #float('-inf'),float('inf')分别表示负无穷和正无穷\n",
    "    for i in range(1,n+1):\n",
    "        qua =X.quantile(i/(n+1))\n",
    "        cut.append(round(qua,4))\n",
    "    cut.append(float('inf'))\n",
    "    woe = list(d4['woe'].round(3))\n",
    "    return d4,iv,cut,woe\n",
    "  \n",
    "dfx1,ivx1,cutx1,woex1 = monoto_bin(data_train['target'],data_train['percentage'],n=10)\n",
    "dfx2,ivx2,cutx2,woex2 = monoto_bin(data_train['target'],data_train['age'],n=10)\n",
    "# dfx4,ivx4,cutx4,woex4 = monoto_bin(data_train['target'],data_train['DebtRatio'],n=10)\n",
    "dfx5,ivx5,cutx5,woex5 = monoto_bin(data_train['target'],data_train['MonthlyIncome'],n=10)\n",
    "\n",
    "plt.bar(range(len(woex1)),woex1)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(range(len(woex2)),woex2)#完全单调，分箱效果不错\n",
    "plt.show()\n",
    "\n",
    "plt.bar(range(len(woex5)),woex5)\n",
    "plt.show()\n",
    "\n",
    "dfx1\n",
    "monoto_bin(data_train['target'],data_train['percentage'],n=10)\n",
    "\n",
    "def self_bin(Y, X, bin):\n",
    "    r = 0\n",
    "    total_bad = Y.sum()\n",
    "    total_good =Y.count()-total_bad  \n",
    "    d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Bucket\": pd.cut(X, bin)})\n",
    "    d2 = d1.groupby('Bucket', as_index = True)\n",
    "    r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "        \n",
    "    d3 = pd.DataFrame(d2.min().X, columns = ['min_' + X.name])\n",
    "    d3['min_' + X.name] = d2.min().X\n",
    "    d3['max_' + X.name] = d2.max().X\n",
    "    d3[Y.name] = d2.sum().Y\n",
    "    d3['total'] = d2.count().Y\n",
    "    #d3[Y.name + '_rate'] = d2.mean().Y\n",
    "    #好坏比，求woe,证据权重，自变量对目标变量有没有影响，什么影响\n",
    "    d3['badattr']=d3[Y.name]/total_bad\n",
    "    d3['goodattr']=(d3['total']-d3[Y.name])/total_good\n",
    "    d3['woe'] = np.log(d3['goodattr']/d3['badattr'])\n",
    "    #iv，信息值，自变量对于目标变量的影响程度\n",
    "    iv = ((d3['goodattr']-d3['badattr'])*d3['woe']).sum()\n",
    "    d4 = (d3.sort_values(by = 'min_' + X.name)).reset_index(drop = True)\n",
    "    print (\"=\" * 80)\n",
    "#     print (d4)\n",
    "    woe = list(d4['woe'].round(3))\n",
    "    return d4,iv,cut,woe\n",
    "  \n",
    "pinf = float('inf')#正无穷大\n",
    "ninf = float('-inf')#负无穷大\n",
    "cutx3 = [ninf, 0, 1, 3, 5, pinf]\n",
    "cutx4 = [ninf,0,0.1,0.35,pinf]\n",
    "cutx6 = [ninf, 1, 2, 3, 5, pinf]\n",
    "cutx7 = [ninf, 0, 1, 3, 5, pinf]\n",
    "cutx8 = [ninf, 0,1,2, 3, pinf]\n",
    "cutx9 = [ninf, 0, 1, 3, pinf]\n",
    "cutx10 = [ninf, 0, 1, 2, 3, 5, pinf]\n",
    "len(cutx5)\n",
    "\n",
    "dfx3, ivx3,woex3 = self_bin(data_train['target'],data_train['30-59'],cutx3)\n",
    "dfx4, ivx4,woex4 = self_bin(data_train['target'],data_train['DebtRatio'],cutx4)\n",
    "dfx6, ivx6,woex6 = self_bin(data_train['target'],data_train['open_loan'],cutx6) \n",
    "dfx7, ivx7,woex7 = self_bin(data_train['target'],data_train['90-'],cutx7)\n",
    "dfx8, ivx8,woex8 = self_bin(data_train['target'],data_train['estate_loan'],cutx8) \n",
    "dfx9, ivx9,woex9 = self_bin(data_train['target'],data_train['60-89'],cutx9)\n",
    "dfx10, ivx10,woex10 = self_bin(data_train['target'],data_train['Dependents'],cutx10)\n",
    "\n",
    "y=[ivx1,ivx2,ivx3,ivx4,ivx5,ivx6,ivx7,ivx8,ivx9,ivx10]\n",
    "index=data_train.columns.drop('target')\n",
    "fig= plt.figure(figsize = (16,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.bar(range(1,11), y, width=0.4,color = 'r',alpha = 0.6)#生成柱状图\n",
    "ax1.set_xticks(range(1,11))\n",
    "ax1.set_xticklabels(index, rotation=0, fontsize=12)\n",
    "ax1.set_ylabel('IV', fontsize=14)\n",
    "#在柱状图上添加数字标签\n",
    "for i, v in enumerate(y):\n",
    "    plt.text(i+1, v+0.01, '%.4f' % v, ha='center', va='bottom', fontsize=12)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "根据IV值判断变量预测能力的标准:\n",
    "< 0.02： useless for predition\n",
    "0.02-0.1： weak predictor\n",
    "0.1-0.3： medium predictor\n",
    "0.3-0.5： strong predictor\n",
    "大于0.5： suspicious or too good to be true\n",
    "\n",
    "\"\"\"\n",
    "#删除掉iv小于0.01的变量，DebtRatio,MonthlyIncome,open_loan,estate_loan,Dependents\n",
    "\n",
    "def change_woe(d,cut,woe):\n",
    "    list=[]\n",
    "    i=0\n",
    "    while i<len(d):\n",
    "        value=d[i]\n",
    "        j=len(cut)-2\n",
    "        m=len(cut)-2\n",
    "        while j>=0:\n",
    "            if value>=cut[j]:\n",
    "                j=-1\n",
    "            else:\n",
    "                j -=1\n",
    "                m -= 1\n",
    "        list.append(woe[m])\n",
    "        i += 1\n",
    "    return list\n",
    "#训练集转化，change_woe函数作用是将每个变量的数据根据其所在区间替换成对应的woe值\n",
    "data_train['percentage'] = pd.Series(change_woe(data_train['percentage'], cutx1, woex1))\n",
    "data_train['age'] = pd.Series(change_woe(data_train['age'], cutx2, woex2))\n",
    "data_train['30-59'] = pd.Series(change_woe(data_train['30-59'], cutx3, woex3))\n",
    "data_train['DebtRatio'] = pd.Series(change_woe(data_train['DebtRatio'], cutx4, woex4))\n",
    "data_train['MonthlyIncome'] = pd.Series(change_woe(data_train['MonthlyIncome'], cutx5, woex5))\n",
    "data_train['open_loan'] = pd.Series(change_woe(data_train['open_loan'], cutx6, woex6))\n",
    "data_train['90-'] = pd.Series(change_woe(data_train['90-'], cutx7, woex7))\n",
    "data_train['estate_loan'] = pd.Series(change_woe(data_train['estate_loan'], cutx8, woex8))\n",
    "data_train['60-89'] = pd.Series(change_woe(data_train['60-89'], cutx9, woex9))\n",
    "data_train['Dependents'] = pd.Series(change_woe(data_train['Dependents'], cutx10, woex10))\n",
    "\n",
    "#删除对target不明显的变量\n",
    "train_X =data_train.drop(['DebtRatio','MonthlyIncome','open_loan','estate_loan','Dependents'],axis=1)\n",
    "# test_X =data_test.drop(['DebtRatio','MonthlyIncome','open_loan','estate_loan','Dependents'],axis=1)\n",
    "\n",
    "#模型建立\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = train_X.drop('target',axis = 1)\n",
    "y = train_X['target']\n",
    "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size = 0.3,random_state = 0)\n",
    "train = pd.concat([train_y,train_x], axis =1)\n",
    "test = pd.concat([test_y,test_x], axis =1)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "lr = LogisticRegression(penalty= 'l1')\n",
    "lr.fit(train_x,train_y)\n",
    "\n",
    "#绘制roc曲线\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# y_pred= lr.predict(train_x)  \n",
    "train_predprob = lr.predict_proba(train_x)[:,1]  \n",
    "test_predprob = lr.predict_proba(test_x)[:,1] \n",
    "FPR,TPR,threshold =roc_curve(test_y,test_predprob)\n",
    "ROC_AUC= auc(FPR,TPR)\n",
    "plt.plot(FPR, TPR, 'b', label='AUC = %0.2f' % ROC_AUC)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.show()\n",
    "\n",
    "# 个人总分=基础分+各部分得分\n",
    "import math\n",
    "B = 20 / math.log(2)\n",
    "A = 600 - B / math.log(20)\n",
    "# 基础分\n",
    "base = round(A+B *lr.intercept_[0], 0)\n",
    "base\n",
    "\n",
    "#计算分数函数\n",
    "def compute_score(coe,woe,factor):\n",
    "    scores=[]\n",
    "    for w in woe:\n",
    "        score=round(coe*w*factor,0)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "x1_percentage = compute_score(lr.coef_[0][0], woex1, B)\n",
    "x2_age = compute_score(lr.coef_[0][1], woex2, B)\n",
    "x4_59 = compute_score(lr.coef_[0][2], woex4, B)\n",
    "x7_90 = compute_score(lr.coef_[0][3], woex7, B)\n",
    "x9_60 = compute_score(lr.coef_[0][4], woex9, B)\n",
    "\n",
    "def change_score(series,cut,score):\n",
    "    list = []\n",
    "    i = 0\n",
    "    while i < len(series):\n",
    "        value = series[i]\n",
    "        j = len(cut) - 2\n",
    "        m = len(cut) - 2\n",
    "        while j >= 0:\n",
    "            if value >= cut[j]:\n",
    "                j = -1\n",
    "            else:\n",
    "                j -= 1\n",
    "                m -= 1\n",
    "        list.append(score[m])\n",
    "        i += 1\n",
    "    return list\n",
    "\n",
    "#导入test数据\n",
    "test1 = pd.read_csv('./data/cs-test.csv')\n",
    "test1.rename(columns=columns,inplace = True)\n",
    "test2 = pd.DataFrame()\n",
    "test2['x1_percentage'] = pd.Series(change_score(test1['percentage'], cutx1, x1_percentage))\n",
    "test2['x2_age'] = pd.Series(change_score(test1['age'], cutx2, x2_age))\n",
    "test2['x4_59'] = pd.Series(change_score(test1['DebtRatio'], cutx4,x4_59))\n",
    "test2['x7_90'] = pd.Series(change_score(test1['90-'], cutx7, x7_90))\n",
    "test2['x9_60'] = pd.Series(change_score(test1['60-89'], cutx9, x9_60))\n",
    "\n",
    "test2['Score'] = test2['x1_percentage'] + test2['x2_age'] + test2['x4_59']+test2['x7_90']+test2['x9_60']+ base\n",
    "sns.distplot(test2['Score'],bins = 30,color = 'r')#分数分布\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
